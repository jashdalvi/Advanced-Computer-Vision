{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dlib\n",
    "from imutils import paths\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"../data/images/FaceRec\"\n",
    "train_dir = os.path.join(dataset_dir,\"trainFaces\")\n",
    "\n",
    "train_imagepaths = list(paths.list_images(train_dir))\n",
    "train_labels = [x.split(os.path.sep)[-2] for x in train_imagepaths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'vikas', 1: 'vaibhaw', 2: 'satya', 3: 'Jash', 4: 'koustubh'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapping = {'vikas': 0,'vaibhaw':1,'satya':2,'Jash':3,'koustubh':4}\n",
    "inv_label_mapping = dict([(v,k) for k,v in label_mapping.items()])\n",
    "inv_label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_face(image,landmarks):\n",
    "    width = 600\n",
    "    height = 600\n",
    "    eye_points_src = [[int(landmarks.part(2).x),int(landmarks.part(2).y)],[int(landmarks.part(0).x),int(landmarks.part(0).y)]]\n",
    "    eye_points_dst = [[int(0.3 * width),int(height/3)],[int(0.7*width),int(height/3)]]\n",
    "\n",
    "    cos_theta = np.cos(60*np.pi/180)\n",
    "    sin_theta = np.sin(60*np.pi/180)\n",
    "\n",
    "    x_src = cos_theta*(eye_points_src[0][0] - eye_points_src[1][0]) - sin_theta*(eye_points_src[0][1] - eye_points_src[1][1]) + eye_points_src[1][0]\n",
    "    y_src = cos_theta*(eye_points_src[0][0] - eye_points_src[1][0]) + sin_theta*(eye_points_src[0][1] - eye_points_src[1][1]) + eye_points_src[1][1]\n",
    "\n",
    "    x_dst = cos_theta*(eye_points_dst[0][0] - eye_points_dst[1][0]) - sin_theta*(eye_points_dst[0][1] - eye_points_dst[1][1]) + eye_points_dst[1][0]\n",
    "    y_dst = cos_theta*(eye_points_dst[0][0] - eye_points_dst[1][0]) + sin_theta*(eye_points_dst[0][1] - eye_points_dst[1][1]) + eye_points_dst[1][1]\n",
    "\n",
    "    eye_points_src.append([x_src,y_src])\n",
    "    eye_points_dst.append([x_dst,y_dst])\n",
    "\n",
    "    eye_points_src = np.int32(eye_points_src).reshape(3,1,2)\n",
    "    eye_points_dst = np.int32(eye_points_dst).reshape(3,1,2)\n",
    "\n",
    "    transform_mat = cv2.estimateAffinePartial2D(eye_points_src,eye_points_dst)[0]\n",
    "\n",
    "    face_aligned = cv2.warpAffine(image,transform_mat,(width,height))\n",
    "    \n",
    "    return face_aligned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = dlib.get_frontal_face_detector()\n",
    "landmark_detector = dlib.shape_predictor(\"../data/models/shape_predictor_5_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_model = cv2.dnn.readNetFromTorch(\"../data/models/openface.nn4.small2.v1.t7\")\n",
    "rec_mean = [0,0,0]\n",
    "rec_size = (96, 96)\n",
    "rec_scale = 1/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_descriptors = []\n",
    "labels = []\n",
    "for (imagepath,label) in zip(train_imagepaths,train_labels):\n",
    "    image = cv2.imread(imagepath)\n",
    "    \n",
    "    image_rgb = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    face_rects = face_detector(image_rgb,0)\n",
    "    \n",
    "    if len(face_rects) == 0:\n",
    "        continue\n",
    "        \n",
    "    x1 = int(face_rects[0].left())\n",
    "    y1 = int(face_rects[0].top())\n",
    "    x2 = int(face_rects[0].right())\n",
    "    y2 = int(face_rects[0].bottom())\n",
    "    \n",
    "    new_rect = dlib.rectangle(x1,y1,x2,y2)\n",
    "    \n",
    "    landmarks = landmark_detector(image_rgb,new_rect)\n",
    "    \n",
    "    face_aligned = align_face(image,landmarks)\n",
    "    \n",
    "    blob = cv2.dnn.blobFromImage(face_aligned,rec_scale,rec_size,rec_mean,False,False)\n",
    "    rec_model.setInput(blob)\n",
    "    face_descriptor = rec_model.forward()\n",
    "    \n",
    "    face_descriptors.append(face_descriptor)\n",
    "    labels.append(label_mapping[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_descriptors = np.vstack(face_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    starting_time = cv2.getTickCount()\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    frame_rgb = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "    face_rects = face_detector(frame_rgb,0)\n",
    "    \n",
    "    if len(face_rects) == 0:\n",
    "        continue\n",
    "        \n",
    "    x1 = int(face_rects[0].left())\n",
    "    y1 = int(face_rects[0].top())\n",
    "    x2 = int(face_rects[0].right())\n",
    "    y2 = int(face_rects[0].bottom())\n",
    "    \n",
    "    new_rect = dlib.rectangle(x1,y1,x2,y2)\n",
    "    \n",
    "    landmarks = landmark_detector(frame_rgb,new_rect)\n",
    "    \n",
    "    face_aligned = align_face(frame,landmarks)\n",
    "    \n",
    "    blob = cv2.dnn.blobFromImage(face_aligned,rec_scale,rec_size,rec_mean,False,False)\n",
    "    rec_model.setInput(blob)\n",
    "    face_descriptor = rec_model.forward()\n",
    "    \n",
    "    distances = np.linalg.norm((face_descriptors - face_descriptor),axis = 1)\n",
    "    \n",
    "    index = np.argmin(distances)\n",
    "    distance = distances[index]\n",
    "    \n",
    "    if distance < 0.8:\n",
    "        person_name = inv_label_mapping[labels[index]]\n",
    "    else:\n",
    "        person_name = \"unknown\"\n",
    "    \n",
    "    fps = cv2.getTickFrequency()/(cv2.getTickCount() - starting_time)\n",
    "    cv2.rectangle(frame,(x1,y1),(x2,y2),(0,255,0))\n",
    "    cv2.putText(frame,\"Name : {} FPS : {:.3f}\".format(person_name,fps),(10,25),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,0,255))\n",
    "    \n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "        \n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
